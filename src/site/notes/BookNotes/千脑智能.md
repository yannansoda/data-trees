---
{"title":"千脑智能","author":"Jeff Hawkins","EndDate":"2025-07-27","publisher":null,"dg-publish":true,"permalink":"/BookNotes/千脑智能/","dgPassFrontmatter":true,"noteIcon":""}
---

[status:: Done]
[format:: kindle]

>[!tip] Back to my [[Index/Some Books I Have Read\|BookList]]

# Comments
竟然是第一次读到Jeff Hawkins的Thousand Brains Theory，概括而言就是大脑由cortical column分布式协同工作，其中每个cortical column都是一个感知-运动系统，在参考系中学习着世界的模型，而协同工作由投票达成共识而完成。不禁会想，如果我读博前读过这个理论（特别是每个模块有相同的计算原理这一点），对研究的思考和理解会不会大不一样。读完这本正好看到一篇对Hawkins的AI公司Numenta的[报道](https://mp.weixin.qq.com/s/z-UFYkegbd986-fyDbzC2w)，期待一下LLM之外的类脑智能。

# Highlights

### 千脑智能理论
- 新脑vs旧脑
	- 区分“旧脑”（情绪、动机）与“新皮层”（思维、感知）
	- 新皮层是我们智能的来源，结构高度统一。
- 新皮层的智能算法
	- 新皮层不是按功能划分的，而是通用的学习机器。
	> 以下是芒卡斯尔文章中的第二段话： 简而言之，运动皮质不存在任何内在的运动，感觉皮质也不存在任何内在的感觉。因此，阐明新皮质中任何一个区域的局部模块回路的工作模式都具有重要的普遍意义。 在这两句话中，芒卡斯尔总结了他文章中提出的主要观点。他认为，新皮质的每一部分都是基于同一原则工作的。从视觉、触觉、语言到高级思维，所有我们认为是智能的东西，从根本上来说都是一样的。 
	- 不同区域可以在输入不同信号的情况下学会做不同的事。
	> 芒卡斯尔指出，这些区域之所以看起来相似，是因为它们都在做着同样的事情。使这些区域有所区别的不是它们的内在功能，而是它们所连接的东西。如果你将一个皮质区与眼睛相连，就得到了视觉；如果你将同一皮质区与耳朵相连，就得到了听觉；如果你将两个不同的皮质区相连，你就得到了高级思维，如语言。然后芒卡斯尔指出，如果我们能发现新皮质所有部分的基本功能，就能理解整个新皮质的工作方式。
	- 每个皮层小柱（cortical column）都能学习完整物体模型。
	> - 达尔文提出，生命的多样性是基于一种基本算法。芒卡斯尔提出，智能的多样性也是基于一种基本算法。
	> - 有意思的一点是，芒卡斯尔和达尔文的观点存在一个有趣的不同之处。达尔文知道算法是什么：进化以随机变异和自然选择为基础。但达尔文并不知道这个算法位于身体的什么位置，直到多年后，人类发现了DNA。相比之下，芒卡斯尔不知道新皮质的算法是什么，也不知道智能的原理是什么，但他知道这种算法在大脑中的具体位置。 那么，关于皮质算法的位置，芒卡斯尔的观点是什么呢？他认为，新皮质的基本单位，即智能的单位，是“皮质柱”。
- 大脑中的世界模型
> - 暂且不管新皮质还能做什么其他事情，我们至少可以肯定地说，它学习了一个令人难以置信的复杂的世界模型。这个模型是我们进行预测、感知和行动的基础。
> - 关于新皮质如何工作的问题，我现在可以给出更精确的表述了：由数千个几乎相同的皮质柱组成的新皮质，是如何通过运动学习世界的预测模型的？ 这就是我和我的团队着手回答的问题。我们相信，如果我们能回答这个问题，就能对新皮质进行逆向工程。我们将了解新皮质的功能以及它是如何实现这一功能的。最终，我们将能够制造出以同样方式工作的智能机器。 
> - 因此，当一个未预测到的输入到达时，多个神经元会同时被激发，但如果输入是预测到的，那么将只有处于预测状态的神经元会发射脉冲信号。这是从新皮质中观察到的一个常见现象：未预测到的输入通常会比预测到的输入引起更大的刺激。
- 大脑中的地图与参考系
	- 大脑通过感觉 + 动作（sensorimotor integration）来学习对象。
	- 感知与“相对于物体的位置”密切相关（类似网格细胞定位）。
	> - 如果我们所知道的一切都存储在参考系中，那么为了回忆存储的知识，我们必须在适当的参考系中激活适当的位置。当神经元激活参考系中一个又一个位置时，思考就会产生，从而让人想起每个位置所存储的内容。我们在思考时所经历的一系列想法类似于我们用手指触摸物体时所感知的一系列感觉，或者我们在小镇上行走时所看到的一系列事物。
	> - 在某种程度上，你的身体只是存在于世界上的另一个物体。新皮质使用相同的基本方法来为你的身体建模，就像为咖啡杯等物体建模一样。但是，与外部物体不同，你的身体是始终存在的。新皮质的很大一部分（即where区域）专门用于为你的身体和你身体周围的空间建模。
	> - 如果所有知识都是以这种方式存储的，那么我们通常所说的“思维”实际上就是在一个空间、一个参考系中移动。你当前的想法，以及任何时刻存储在你大脑中的东西，都由参考系中的当前位置决定。
	> - 到目前为止，我已经介绍了参考系的四种用途，一种用于旧脑，三种用于新皮质。旧脑中的参考系学习环境地图。新皮质里what柱中的参考系学习实物地图。新皮质里where柱中的参考系学习我们身体周围空间的地图。此外，新皮质里非感觉皮质柱中的参考系学习概念地图。
- 千脑智能理论（The Thousand Brains Theory）
	- 智能不是一个大模型，而是成千上万“小模型”协同投票。
	> - 这就是我们称其为“千脑智能理论”的原因：关于任何特定物体的知识都分布在成千上万个互补的模型中。
	> - 绑定问题基于这样一个假设，即新皮质对世界上的每个物体都有一个单一的模型。而千脑智能理论认为，世界上的每个物体都有数千个模型。大脑的各种输入不会被绑定或聚合成单个模型。皮质柱具有不同类型的输入，一根皮质柱代表视网膜的一小部分，而另一根皮质柱代表更大的部分，这些因素都无关紧要。视网膜有没有洞，就像你的手指之间有没有缝隙一样，都不重要。投射到V1区的模式可能会被扭曲和混淆，这也无关紧要，因为新皮质的任何一部分都不会试图重新组合这种混乱的表征。千脑智能理论的投票机制解释了为什么我们有一个一致而并不扭曲的感知。它还解释了在一种感觉模态中识别物体是如何导致在其他感官模式中进行预测的。
### 机器智能
- 并不智能的人工智能
	- 当前 AI 缺乏世界模型（world model），无法灵活泛化。
	- 深度学习依赖大量数据与模式匹配，缺乏因果理解。
- 机器智能的未来
	- AI 未来应模仿新皮层的架构：
	    - 模块化建模
	    - 空间编码
	    - 并行协作
	
	> - 如今的神经网络依赖于辛顿在20世纪80年代提出的思想。近年来，辛顿开始对该研究领域持批判态度，由于深度学习网络无法感知位置信息，他认为深度学习网络无法学习世界的模型。本质上，这和我提出的批评是一样的：人工智能需要参考系。辛顿提出了一种解决该问题的方案——胶囊（capsules）(6)。胶囊有望大幅提高神经网络的性能，但到目前为止，它们还没有在人工智能的主流应用中流行起来。胶囊是否会成功？未来的人工智能是否依赖于我提出的类似于网格细胞的机制？这些问题还有待探究。无论如何，参考系对于智能来说不可或缺。
	> - 人类之所以聪明，不是因为我们能把一件事做得特别好，而是因为我们能学会做几乎任何事。人类智能的极端灵活性需要本章中描述的特性：**持续学习、通过运动学习、多重模型、使用参考系存储知识并生成面向目标的行为。**
	> - 旧脑中的神经元在产生恐惧和情感时，会向体内释放激素和其他化学物质。大脑新皮质可能会帮助旧脑决定何时释放这些化学物质。但如果没有旧脑，我们就不会感知到恐惧或悲伤。对死亡的恐惧和对失去亲人的悲伤对于具有意识和智能的机器而言并不是必要的。除非我们特地赋予机器同样的恐惧和情感，否则它们根本不会在意自己是否被关闭、拆卸或报废。
	> - 在创造智能机器时，我们不必复制人类大脑的所有功能。新脑，即大脑新皮质，是体现人类智能的器官，智能机器需要具备与之相当的东西。至于大脑的其他部分，我们可以选出一些我们想要的部分。
	> - 设计智能机器可以从三个部分着手：具身（embodiment）、旧脑部分、大脑新皮质。每个组件都有很大的自由度，因此将会产生许多类型的智能机器。
	> - 无论大脑有多大，运行速度有多快，获取新知识和技能都需要时间。在数学等领域，智能机器可以比人类学得更快。然而，在大多数领域，学习的速度会受到与世界进行客观互动这一需要的限制。因此，机器不可能突然知道得比我们多，智能爆炸的威胁不可能出现。
	> - 但谈到机器智能的风险与回报，我认为需要弄清楚三个概念之间的区别：复制、动机和智能。
	> - 我们需要铭记两个要点：一是大脑只认识真实世界的一个部分（子集），二是我们感知到的只是这个世界的模型，并不是真实世界本身。
	> - 人类的智能之所以远超其他物种，人类这个物种之所以能自我启蒙，原因就在于我们对世界模型的拓展远超我们直接可以观察到的范围。这种知识的拓展是通过各种各样的工具，如船、显微镜和望远镜等，以及各种形式的交流，如书面语和图片等实现的。
    

#### **Chapter 7: Morality and the Brain**

- 人类智能与道德判断是两回事。
    
- 要构建安全的 AGI，需区分智能本身与目标系统（即不让 AI 变成“有欲望的智能”）
